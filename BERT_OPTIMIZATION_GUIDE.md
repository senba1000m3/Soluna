# BERT æ¨è–¦å¼•æ“å„ªåŒ–æŒ‡å—

## ğŸ“‹ ç›®éŒ„

1. [å•é¡Œè¨ºæ–·](#å•é¡Œè¨ºæ–·)
2. [å„ªåŒ–æ–¹æ¡ˆç¸½è¦½](#å„ªåŒ–æ–¹æ¡ˆç¸½è¦½)
3. [å¿«å–ç­–ç•¥](#å¿«å–ç­–ç•¥)
4. [ä½¿ç”¨æ–¹å¼](#ä½¿ç”¨æ–¹å¼)
5. [æ•ˆèƒ½æå‡å°æ¯”](#æ•ˆèƒ½æå‡å°æ¯”)
6. [å®šæœŸç¶­è­·](#å®šæœŸç¶­è­·)
7. [é€²éšå„ªåŒ–](#é€²éšå„ªåŒ–)

---

## å•é¡Œè¨ºæ–·

### ç•¶å‰å•é¡Œ

- âœ… **è²å„ªè³‡æ–™å¿«å–**: å·²å¯¦ç¾ï¼ŒåŠ é€Ÿ API èª¿ç”¨
- âŒ **BERT æ¯æ¬¡é‡æ–°æ¨ç†**: 500+ ç­†è³‡æ–™å¡åœ¨ 5%
- âŒ **ç„¡æ‰¹æ¬¡è™•ç†**: é€å€‹è™•ç†å‹•ç•«æ•ˆç‡ä½
- âŒ **CPU æ¨ç†æ…¢**: æ²’æœ‰ GPU åŠ é€Ÿ
- âŒ **ç„¡æ¨¡å‹å„ªåŒ–**: æ²’æœ‰ FP16/é‡åŒ–

### æ•ˆèƒ½ç“¶é ¸åˆ†æ

```
åŸå§‹æµç¨‹ (æ¯æ¬¡æ¨è–¦éƒ½è¦åš):
1. è¼‰å…¥ä½¿ç”¨è€…åˆ—è¡¨ (1000 ç­†) â†’ 2-5 ç§’
2. BERT ID æ˜ å°„ (1000 æ¬¡) â†’ 5-10 ç§’
3. BERT æ¨ç† (CPU) â†’ 30-120 ç§’ âš ï¸ ä¸»è¦ç“¶é ¸
4. ç‰¹å¾µæå– (1000 æ¬¡) â†’ 10-20 ç§’
5. è©•åˆ†æ–°ç•ª (50 éƒ¨) â†’ 5-10 ç§’
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ç¸½æ™‚é–“: 52-165 ç§’ (å¡åœ¨ 5% å°±æ˜¯é€™è£¡)
```

---

## å„ªåŒ–æ–¹æ¡ˆç¸½è¦½

### æ–¹æ¡ˆ 1: é è¨“ç·´ + å¿«å– (æ¨è–¦ â­â­â­â­â­)

**ä½ çš„æƒ³æ³•å®Œå…¨æ­£ç¢ºï¼**

```
æ–°æµç¨‹ (é¦–æ¬¡):
1. é è¨“ç·´éšæ®µ (æ¯é€±ä¸€æ¬¡æˆ–ä½¿ç”¨è€…åˆ—è¡¨è®ŠåŒ–æ™‚)
   - ä½¿ç”¨è€… A: BERT æ¨ç† â†’ å¿«å–åˆ°è³‡æ–™åº«
   - ä½¿ç”¨è€… B: BERT æ¨ç† â†’ å¿«å–åˆ°è³‡æ–™åº«
   
æ–°æµç¨‹ (ä¹‹å¾Œæ¯æ¬¡æ¨è–¦):
1. æª¢æŸ¥å¿«å– â†’ 0.1 ç§’ âœ…
2. ç›´æ¥ä½¿ç”¨å¿«å–çµæœ â†’ 0.5 ç§’ âœ…
3. è©•åˆ†æ–°ç•ª (50 éƒ¨) â†’ 5-10 ç§’
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ç¸½æ™‚é–“: 5-11 ç§’ (é€Ÿåº¦æå‡ 10-15 å€ï¼)
```

### æ–¹æ¡ˆ 2: GPU åŠ é€Ÿ

```python
# ä½¿ç”¨ GPU å¯ä»¥æå‡ 5-10 å€é€Ÿåº¦
device = "cuda" if torch.cuda.is_available() else "cpu"
model = model.to(device)
```

**æ•ˆèƒ½æå‡**: CPU 30-120 ç§’ â†’ GPU 3-15 ç§’

### æ–¹æ¡ˆ 3: FP16 åŠç²¾åº¦

```python
# åœ¨ GPU ä¸Šå•Ÿç”¨ FP16ï¼Œé€Ÿåº¦å†æå‡ 2 å€
if device == "cuda":
    model = model.half()
```

**æ•ˆèƒ½æå‡**: GPU 3-15 ç§’ â†’ GPU FP16 1.5-7.5 ç§’

### æ–¹æ¡ˆ 4: æ‰¹æ¬¡è™•ç†

```python
# åŸæœ¬: é€å€‹è™•ç† 1000 ç­†
for anime_id in anime_ids:  # 1000 æ¬¡å¾ªç’°
    process(anime_id)

# å„ªåŒ–: æ‰¹æ¬¡è™•ç†
for batch in batches(anime_ids, batch_size=32):  # 32 æ¬¡å¾ªç’°
    process_batch(batch)
```

**æ•ˆèƒ½æå‡**: æ¸›å°‘å¾ªç’°é–‹éŠ· 30-50%

---

## å¿«å–ç­–ç•¥

### è³‡æ–™åº«çµæ§‹

å·²æ–°å¢å…©å€‹å¿«å–è¡¨ï¼š

#### 1. `BERTUserProfile` - ä½¿ç”¨è€… Profile å¿«å–

```python
{
    "anilist_username": "myusername",
    "anilist_id": 123456,
    "user_anime_ids": [1, 2, 3, ...],  # JSON é™£åˆ—
    "bert_features": {                   # BERT æå–çš„ç‰¹å¾µ
        "genres": {"Action": 25, "Drama": 15, ...},
        "tags": {"Shounen": 30, ...},
        "studios": {"Ufotable": 10, ...}
    },
    "profile_hash": "abc123...",         # ç”¨æ–¼æª¢æ¸¬åˆ—è¡¨è®ŠåŒ–
    "updated_at": "2025-01-15 10:30:00",
    "anime_count": 1000
}
```

#### 2. `BERTRecommendationCache` - æ¨è–¦çµæœå¿«å–

```python
{
    "anilist_username": "myusername",
    "profile_hash": "abc123...",
    "recommendations": [                 # Top 100 æ¨è–¦
        {"anime_id": 456, "score": 0.95},
        {"anime_id": 789, "score": 0.89},
        ...
    ],
    "top_k": 100,
    "cached_at": "2025-01-15 10:30:00",
    "cache_hit_count": 25                # è¢«ä½¿ç”¨æ¬¡æ•¸
}
```

### å¿«å–é‚è¼¯

```
ä½¿ç”¨è€…è«‹æ±‚æ¨è–¦
    â†“
æª¢æŸ¥å¿«å–æ˜¯å¦å­˜åœ¨ & æœªéæœŸ (é è¨­ 7 å¤©)
    â†“
â”Œâ”€â”€â”€ YES â”€â”€â”€â†’ ç›´æ¥è¿”å›å¿«å–çµæœ (0.1 ç§’) âœ…
â”‚
â””â”€â”€â”€ NO â”€â”€â”€â”€â†’ BERT æ¨ç† â†’ å„²å­˜å¿«å– â†’ è¿”å›çµæœ (30-120 ç§’)
              (ä¸‹æ¬¡å°±å¿«äº†ï¼)
```

### å¿«å–å¤±æ•ˆæ©Ÿåˆ¶

å¿«å–æœƒåœ¨ä»¥ä¸‹æƒ…æ³å¤±æ•ˆï¼š

1. **æ™‚é–“éæœŸ**: è¶…é 7 å¤©ï¼ˆå¯è¨­å®šï¼‰
2. **åˆ—è¡¨è®ŠåŒ–**: ä½¿ç”¨è€…æ–°å¢/åˆªé™¤å‹•ç•«ï¼ˆprofile_hash æ”¹è®Šï¼‰
3. **æ‰‹å‹•æ¸…é™¤**: å¼·åˆ¶æ›´æ–° (`--force` åƒæ•¸)

---

## ä½¿ç”¨æ–¹å¼

### 1. è³‡æ–™åº«é·ç§»

é¦–å…ˆæ›´æ–°è³‡æ–™åº«çµæ§‹ï¼š

```bash
cd Lunaris
python database.py  # è‡ªå‹•å»ºç«‹æ–°è¡¨
```

### 2. é è¨“ç·´å–®ä¸€ä½¿ç”¨è€…

```bash
# é è¨“ç·´ä½ çš„å¸³è™Ÿ
python bert_pretrain_users.py --username your_anilist_username

# ä½¿ç”¨ GPU åŠ é€Ÿï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
python bert_pretrain_users.py --username your_anilist_username --use-gpu

# å¼·åˆ¶æ›´æ–°ï¼ˆå¿½ç•¥ç¾æœ‰å¿«å–ï¼‰
python bert_pretrain_users.py --username your_anilist_username --force
```

**é æœŸè¼¸å‡º**:
```
ğŸš€ BERT ä½¿ç”¨è€… Profile é è¨“ç·´å™¨
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ”§ åˆå§‹åŒ–è³‡æ–™åº«...
ğŸ”„ è¼‰å…¥ BERT æ¨¡å‹...
âœ… BERT æ¨¡å‹è¼‰å…¥å®Œæˆï¼

ğŸ“ è™•ç†ä½¿ç”¨è€…: your_username
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“¡ å¾ AniList å–å¾—ä½¿ç”¨è€…è³‡æ–™...
  âœ“ ä½¿ç”¨è€… ID: 123456
ğŸ“š å–å¾—ä½¿ç”¨è€…å‹•ç•«åˆ—è¡¨...
  âœ“ å‹•ç•«æ•¸é‡: 1000
  âœ“ æœ‰æ•ˆå‹•ç•« ID: 987

ğŸ¤– é–‹å§‹ BERT æ¨ç†å’Œå¿«å–...
ğŸ¯ å„ªåŒ–ç‰ˆ BERT æ¨è–¦å¼•æ“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“‹ éšæ®µ 1/4: ID æ˜ å°„
  âœ“ æˆåŠŸæ˜ å°„ 850/987 å€‹ ID
ğŸ“‹ éšæ®µ 2/4: BERT æ¨ç†
  âœ“ æ¨ç†å®Œæˆ (12.34 ç§’)
ğŸ“‹ éšæ®µ 3/4: æå–ç‰¹å¾µä¸¦å¿«å– Profile
ğŸ’¾ å„²å­˜ Profile å¿«å–: your_username
ğŸ“‹ éšæ®µ 4/4: å¿«å–æ¨è–¦çµæœ
ğŸ’¾ å„²å­˜æ¨è–¦å¿«å–: your_username

ğŸ‰ æ¨è–¦å®Œæˆï¼å…± 100 å€‹æ¨è–¦
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… ä½¿ç”¨è€… your_username è™•ç†æˆåŠŸ
```

### 3. æ‰¹æ¬¡é è¨“ç·´æ‰€æœ‰ä½¿ç”¨è€…

```bash
# æ‰¹æ¬¡è™•ç†è³‡æ–™åº«ä¸­æ‰€æœ‰ä½¿ç”¨è€…
python bert_pretrain_users.py --batch

# ä½¿ç”¨ GPU å’Œè¼ƒå¤§æ‰¹æ¬¡
python bert_pretrain_users.py --batch --use-gpu --batch-size 64

# å¼·åˆ¶æ›´æ–°æ‰€æœ‰ä½¿ç”¨è€…ï¼ˆé‡å»ºæ‰€æœ‰å¿«å–ï¼‰
python bert_pretrain_users.py --batch --force
```

### 4. åœ¨æ¨è–¦ç³»çµ±ä¸­ä½¿ç”¨

ä¿®æ”¹ `hybrid_recommendation_engine.py`:

```python
# èˆŠç‰ˆ (ä¸å»ºè­°)
from bert_recommender import BERTRecommender
bert = BERTRecommender(...)

# æ–°ç‰ˆ (æ¨è–¦)
from bert_recommender_optimized import OptimizedBERTRecommender
bert = OptimizedBERTRecommender(
    model_path="path/to/model.pth",
    device="auto",          # è‡ªå‹•é¸æ“‡ GPU/CPU
    use_fp16=True,          # GPU ä¸Šå•Ÿç”¨ FP16
    batch_size=32,          # æ‰¹æ¬¡å¤§å°
    cache_expiry_days=7,    # å¿«å– 7 å¤©
    db_session=session      # è³‡æ–™åº« session
)

# ç²å–æ¨è–¦ï¼ˆè‡ªå‹•ä½¿ç”¨å¿«å–ï¼‰
recommendations = bert.get_recommendations(
    user_anime_ids=anime_ids,
    username="myusername",      # å¿…å¡«ï¼Œç”¨æ–¼å¿«å–
    anilist_id=123456,          # å¿…å¡«ï¼Œç”¨æ–¼å¿«å–
    top_k=50,
    force_refresh=False         # æ˜¯å¦å¼·åˆ¶åˆ·æ–°
)
```

### 5. å®šæœŸæ›´æ–°å¿«å– (Cron Job)

å»ºè­°æ¯é€±åŸ·è¡Œä¸€æ¬¡æ‰¹æ¬¡æ›´æ–°ï¼š

**Windows (Task Scheduler)**:
```powershell
# å»ºç«‹æ’ç¨‹ä»»å‹™ï¼ˆæ¯é€±æ—¥å‡Œæ™¨ 3:00ï¼‰
schtasks /create /tn "BERT_Weekly_Update" /tr "python E:\Path\To\Lunaris\bert_pretrain_users.py --batch --use-gpu" /sc weekly /d SUN /st 03:00
```

**Linux/Mac (Crontab)**:
```bash
# ç·¨è¼¯ crontab
crontab -e

# æ–°å¢æ’ç¨‹ï¼ˆæ¯é€±æ—¥å‡Œæ™¨ 3:00ï¼‰
0 3 * * 0 cd /path/to/Lunaris && /usr/bin/python3 bert_pretrain_users.py --batch --use-gpu >> bert_update.log 2>&1
```

### 6. æ¸…ç†éæœŸå¿«å–

```bash
# æ¸…ç† 30 å¤©å‰çš„å¿«å–
python bert_pretrain_users.py --cleanup --expiry-days 30

# æ¸…ç† 60 å¤©å‰çš„å¿«å–
python bert_pretrain_users.py --cleanup --expiry-days 60
```

---

## æ•ˆèƒ½æå‡å°æ¯”

### å ´æ™¯ 1: é¦–æ¬¡æ¨è–¦ (ç„¡å¿«å–)

| å„ªåŒ–é …ç›® | åŸå§‹ | å„ªåŒ–å¾Œ | æå‡å€æ•¸ |
|---------|------|--------|---------|
| **åŸºç¤ (CPU)** | 120 ç§’ | 120 ç§’ | 1x |
| + GPU | 120 ç§’ | 15 ç§’ | **8x** |
| + FP16 | 120 ç§’ | 7.5 ç§’ | **16x** |
| + æ‰¹æ¬¡è™•ç† | 120 ç§’ | 5 ç§’ | **24x** |

### å ´æ™¯ 2: å¾ŒçºŒæ¨è–¦ (æœ‰å¿«å–)

| é …ç›® | åŸå§‹ | å„ªåŒ–å¾Œ | æå‡å€æ•¸ |
|------|------|--------|---------|
| BERT æ¨ç† | 120 ç§’ | 0.1 ç§’ | **1200x** |
| ç¸½æ¨è–¦æ™‚é–“ | 150 ç§’ | 10 ç§’ | **15x** |

### å ´æ™¯ 3: 1000 ç­†è³‡æ–™ (ä½ çš„æƒ…æ³)

```
åŸå§‹æµç¨‹:
- è¼‰å…¥åˆ—è¡¨: 5 ç§’
- BERT æ¨ç†: 120 ç§’ (å¡åœ¨ 5% çš„åœ°æ–¹ï¼)
- è©•åˆ†: 10 ç§’
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ç¸½æ™‚é–“: 135 ç§’

å„ªåŒ–æµç¨‹ (é è¨“ç·´ + å¿«å–):
- æª¢æŸ¥å¿«å–: 0.1 ç§’ âœ…
- è¼‰å…¥å¿«å–: 0.5 ç§’ âœ…
- è©•åˆ†: 10 ç§’
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ç¸½æ™‚é–“: 10.6 ç§’ (å¿« 12.7 å€ï¼)
```

### å¯¦éš›æ¸¬è©¦çµæœ (é æœŸ)

åŸºæ–¼ä½ çš„ 1000 ç­†è³‡æ–™ï¼š

| å ´æ™¯ | æ™‚é–“ | è®€æ¢ |
|------|------|------|
| **åŸå§‹ (é¦–æ¬¡)** | 135 ç§’ | å¡åœ¨ 5% âŒ |
| **å„ªåŒ– + GPU (é¦–æ¬¡)** | 18 ç§’ | é †æš¢ âœ… |
| **å„ªåŒ– + å¿«å– (ç¬¬ 2 æ¬¡)** | 10 ç§’ | é †æš¢ âœ… |

---

## å®šæœŸç¶­è­·

### æ¯é€±ä»»å‹™ (è‡ªå‹•åŒ–)

```bash
# æ›´æ–°æ‰€æœ‰ä½¿ç”¨è€…çš„ Profile å’Œæ¨è–¦
python bert_pretrain_users.py --batch --use-gpu
```

### æ¯æœˆä»»å‹™

```bash
# æ¸…ç†éæœŸå¿«å–
python bert_pretrain_users.py --cleanup --expiry-days 30

# æª¢æŸ¥å¿«å–çµ±è¨ˆ
python manage_bert_cache.py --stats
```

### ä½¿ç”¨è€…åˆ—è¡¨è®ŠåŒ–æ™‚

ç•¶ä½¿ç”¨è€…æ–°å¢/åˆªé™¤å¤§é‡å‹•ç•«æ™‚ï¼ˆä¾‹å¦‚ 50+ éƒ¨ï¼‰ï¼Œå»ºè­°æ‰‹å‹•æ›´æ–°ï¼š

```bash
python bert_pretrain_users.py --username affected_user --force
```

---

## é€²éšå„ªåŒ–

### 1. å¤šåŸ·è¡Œç·’é è¨“ç·´

å°æ–¼å¤§é‡ä½¿ç”¨è€…ï¼Œå¯ä»¥å¹³è¡Œè™•ç†ï¼š

```python
# å»ºç«‹ bert_pretrain_users_parallel.py
import asyncio
from concurrent.futures import ThreadPoolExecutor

async def pretrain_parallel(usernames, max_workers=4):
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        tasks = [
            executor.submit(pretrain_user, username)
            for username in usernames
        ]
        for future in tqdm(tasks):
            future.result()
```

### 2. Redis å¿«å– (å¯é¸)

å¦‚æœéœ€è¦æ›´å¿«çš„å¿«å–å­˜å–ï¼š

```python
import redis
r = redis.Redis(host='localhost', port=6379, db=0)

# å¿«å–æ¨è–¦çµæœ
r.setex(
    f"bert_rec:{username}:{profile_hash}",
    604800,  # 7 å¤©
    json.dumps(recommendations)
)
```

### 3. ONNX Runtime (ç”Ÿç”¢ç’°å¢ƒ)

è½‰æ›ç‚º ONNX æ ¼å¼å¯é€²ä¸€æ­¥æå‡ 2-3 å€é€Ÿåº¦ï¼š

```python
# è½‰æ›æ¨¡å‹
torch.onnx.export(model, dummy_input, "model.onnx")

# ä½¿ç”¨ ONNX Runtime
import onnxruntime as ort
session = ort.InferenceSession("model.onnx")
```

### 4. æ¨¡å‹é‡åŒ–

æ¸›å°‘æ¨¡å‹å¤§å°å’Œæ¨ç†æ™‚é–“ï¼š

```python
# INT8 é‡åŒ–
quantized_model = torch.quantization.quantize_dynamic(
    model, {torch.nn.Linear}, dtype=torch.qint8
)
```

### 5. å¢é‡æ›´æ–°

åªæ›´æ–°è®ŠåŒ–çš„éƒ¨åˆ†ï¼Œè€Œä¸æ˜¯é‡æ–°è¨ˆç®—æ•´å€‹ Profileï¼š

```python
def incremental_update(old_profile, new_anime_ids):
    """åªè™•ç†æ–°å¢çš„å‹•ç•«"""
    new_ids = set(new_anime_ids) - set(old_profile['anime_ids'])
    if len(new_ids) < 10:  # è®ŠåŒ–ä¸å¤§
        # å¢é‡æ›´æ–°
        update_features(old_profile, new_ids)
    else:
        # å®Œæ•´é‡ç®—
        rebuild_profile(new_anime_ids)
```

---

## ç›£æ§èˆ‡é™¤éŒ¯

### æª¢è¦–å¿«å–çµ±è¨ˆ

```python
# åœ¨æ¨è–¦å™¨ä¸­æª¢è¦–çµ±è¨ˆ
bert.print_stats()

# è¼¸å‡º:
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š BERT æ¨è–¦å™¨æ•ˆèƒ½çµ±è¨ˆ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#   å¿«å–å‘½ä¸­: 45
#   å¿«å–æœªå‘½ä¸­: 5
#   å¿«å–å‘½ä¸­ç‡: 90.0%
#   æ¨ç†æ¬¡æ•¸: 5
#   å¹³å‡æ¨ç†æ™‚é–“: 12.34s
#   è¨­å‚™: cuda:0
#   FP16: å•Ÿç”¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### è¨˜éŒ„æª”

æ‰€æœ‰æ“ä½œéƒ½æœƒè¨˜éŒ„åˆ° `bert_pretrain.log`:

```log
2025-01-15 10:30:00 - INFO - Processing user: myusername
2025-01-15 10:30:05 - INFO - Cache HIT for user myusername
2025-01-15 10:30:05 - INFO - Returned 50 recommendations from cache
```

### æ•ˆèƒ½åˆ†æ

```python
import cProfile
cProfile.run('bert.get_recommendations(...)', 'profile_stats')

# åˆ†æçµæœ
import pstats
p = pstats.Stats('profile_stats')
p.sort_stats('cumulative').print_stats(10)
```

---

## å¸¸è¦‹å•é¡Œ

### Q1: å¿«å–æœƒä½”ç”¨å¤šå°‘ç©ºé–“ï¼Ÿ

**A**: æ¯å€‹ä½¿ç”¨è€…ç´„ 50-200 KBï¼š
- Profile: ~20 KB
- Top 100 æ¨è–¦: ~30 KB
- 1000 å€‹ä½¿ç”¨è€… â‰ˆ 50-200 MB (å¾ˆå°ï¼)

### Q2: å¤šä¹…æ›´æ–°ä¸€æ¬¡å¿«å–ï¼Ÿ

**A**: å»ºè­°ç­–ç•¥ï¼š
- **ä¸»å‹•æ›´æ–°**: æ¯é€±ä¸€æ¬¡ï¼ˆCron Jobï¼‰
- **è¢«å‹•æ›´æ–°**: ä½¿ç”¨è€…åˆ—è¡¨è®ŠåŒ–æ™‚è‡ªå‹•æª¢æ¸¬
- **å¼·åˆ¶æ›´æ–°**: æ¨¡å‹æ›´æ–°å¾ŒåŸ·è¡Œ `--force`

### Q3: æ²’æœ‰ GPU æ€éº¼è¾¦ï¼Ÿ

**A**: 
1. ä½¿ç”¨é è¨“ç·´ç­–ç•¥ä»èƒ½ç²å¾— 10-15 å€æå‡
2. è€ƒæ…®ç§Ÿç”¨é›²ç«¯ GPUï¼ˆAWS/GCP/Colabï¼‰
3. ä½¿ç”¨ CPU é‡åŒ–æ¨¡å‹

### Q4: è²å„ªå¿«å–å’Œ BERT å¿«å–æœ‰ä»€éº¼å€åˆ¥ï¼Ÿ

**A**:
- **è²å„ªå¿«å–**: åŠ é€Ÿ API èª¿ç”¨ï¼ˆç¶²è·¯ I/Oï¼‰
- **BERT å¿«å–**: åŠ é€Ÿæ¨¡å‹æ¨ç†ï¼ˆé‹ç®—å¯†é›†ï¼‰
- å…©è€…äº’è£œï¼Œéƒ½å¾ˆé‡è¦ï¼

### Q5: ç‚ºä»€éº¼ç¬¬ä¸€æ¬¡é‚„æ˜¯æœƒæ…¢ï¼Ÿ

**A**: ç¬¬ä¸€æ¬¡å¿…é ˆåŸ·è¡Œ BERT æ¨ç†ä¾†å»ºç«‹å¿«å–ã€‚è§£æ±ºæ–¹æ¡ˆï¼š
1. ä½¿ç”¨é è¨“ç·´è…³æœ¬æå‰è™•ç†
2. åœ¨æ·±å¤œ/ä½å³°æ™‚æ®µæ‰¹æ¬¡è™•ç†
3. ä½¿ç”¨ GPU åŠ é€Ÿé¦–æ¬¡æ¨ç†

---

## ç¸½çµ

### æ¨è–¦å¯¦æ–½æ­¥é©Ÿ

1. âœ… **ç«‹å³å¯¦æ–½**: ä½¿ç”¨é è¨“ç·´ + å¿«å–ç­–ç•¥
   ```bash
   python bert_pretrain_users.py --username your_username --use-gpu
   ```

2. âœ… **æœ¬é€±å¯¦æ–½**: è¨­å®šå®šæœŸæ›´æ–°
   ```bash
   # æ¯é€±æ—¥è‡ªå‹•æ›´æ–°æ‰€æœ‰ä½¿ç”¨è€…
   (è¨­å®š Cron Job æˆ– Task Scheduler)
   ```

3. â³ **æœªä¾†å„ªåŒ–**: GPU + FP16 + æ‰¹æ¬¡è™•ç†
   - è³¼è²·/ç§Ÿç”¨ GPU
   - æˆ–ä½¿ç”¨ Google Colab å…è²» GPU

### é æœŸæ•ˆæœ

å°æ–¼ä½ çš„ 1000 ç­†è³‡æ–™æƒ…æ³ï¼š

| é …ç›® | å„ªåŒ–å‰ | å„ªåŒ–å¾Œ | æ”¹å–„ |
|------|--------|--------|------|
| é¦–æ¬¡æ¨è–¦ | 135 ç§’ (å¡ä½) | 18 ç§’ (GPU) | **7.5x** |
| å¾ŒçºŒæ¨è–¦ | 135 ç§’ | 10 ç§’ (å¿«å–) | **13.5x** |
| ä½¿ç”¨è€…é«”é©— | âŒ å¡åœ¨ 5% | âœ… é †æš¢ | å¤§å¹…æ”¹å–„ |

### é‡è¦æé†’

1. **è¨˜å¾—å®šæœŸæ›´æ–°**: è¨­å®šæ¯é€±è‡ªå‹•åŸ·è¡Œ
2. **ç›£æ§å¿«å–å‘½ä¸­ç‡**: ç›®æ¨™ > 80%
3. **æ¸…ç†éæœŸå¿«å–**: æ¯æœˆåŸ·è¡Œä¸€æ¬¡
4. **æ¨¡å‹æ›´æ–°å¾Œ**: åŸ·è¡Œ `--force` é‡å»ºæ‰€æœ‰å¿«å–

---

## åƒè€ƒè³‡æº

- [BERT4Rec è«–æ–‡](https://arxiv.org/abs/1904.06690)
- [PyTorch å„ªåŒ–æŒ‡å—](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html)
- [ONNX Runtime æ–‡æª”](https://onnxruntime.ai/docs/)
- [åŸå§‹ BERT Workflow æ–‡æª”](./BERT_WORKFLOW.md)

---

**éœ€è¦å”åŠ©ï¼Ÿ** æª¢æŸ¥ `bert_pretrain.log` æˆ–é–‹å•Ÿ Issueï¼

Happy Optimizing! ğŸš€