"""
æª¢æŸ¥ BERT è¨“ç·´ç‹€æ…‹å’Œæ•¸æ“šçš„è…³æœ¬
ç”¨æ–¼è¨ºæ–·è¨“ç·´æ˜¯å¦æ­£ç¢ºä½¿ç”¨æ•¸æ“š
"""

import os
from pathlib import Path

import numpy as np
import torch
from sqlmodel import Session, create_engine, select

from prepare_bert_dataset import BERTAnime, BERTUserAnimeList

BERT_DB_URL = "sqlite:///bert.db"


def check_database():
    """æª¢æŸ¥è³‡æ–™åº«å…§å®¹"""
    print("\n" + "=" * 80)
    print("ğŸ“Š æª¢æŸ¥è³‡æ–™åº«")
    print("=" * 80)

    engine = create_engine(BERT_DB_URL, echo=False)

    with Session(engine) as session:
        # æª¢æŸ¥å‹•ç•«æ•¸é‡
        animes = session.exec(select(BERTAnime)).all()
        print(f"âœ“ å‹•ç•«ç¸½æ•¸: {len(animes)}")

        # æª¢æŸ¥ä½¿ç”¨è€…è¨˜éŒ„
        user_lists = session.exec(select(BERTUserAnimeList)).all()
        print(f"âœ“ ä½¿ç”¨è€…å‹•ç•«è¨˜éŒ„: {len(user_lists)}")

        # çµ±è¨ˆä½¿ç”¨è€…æ•¸é‡
        user_ids = set([entry.user_id for entry in user_lists])
        print(f"âœ“ ä¸é‡è¤‡ä½¿ç”¨è€…: {len(user_ids)}")

        # çµ±è¨ˆæ¯å€‹ä½¿ç”¨è€…çš„è¨˜éŒ„æ•¸
        user_counts = {}
        for entry in user_lists:
            user_id = entry.user_id
            user_counts[user_id] = user_counts.get(user_id, 0) + 1

        if user_counts:
            print(f"âœ“ å¹³å‡æ¯ä½ä½¿ç”¨è€…è¨˜éŒ„æ•¸: {np.mean(list(user_counts.values())):.1f}")
            print(f"âœ“ æœ€å¤šè¨˜éŒ„çš„ä½¿ç”¨è€…: {max(user_counts.values())} ç­†")
            print(f"âœ“ æœ€å°‘è¨˜éŒ„çš„ä½¿ç”¨è€…: {min(user_counts.values())} ç­†")

        # æª¢æŸ¥ç‹€æ…‹åˆ†å¸ƒ
        status_counts = {}
        for entry in user_lists:
            status = entry.status or "UNKNOWN"
            status_counts[status] = status_counts.get(status, 0) + 1

        print("\nğŸ“ˆ ç‹€æ…‹åˆ†å¸ƒ:")
        for status, count in sorted(
            status_counts.items(), key=lambda x: x[1], reverse=True
        ):
            percentage = (count / len(user_lists)) * 100
            print(f"  {status:15s}: {count:5d} ({percentage:5.1f}%)")

    return len(animes), len(user_lists), len(user_ids)


def check_training_data():
    """æª¢æŸ¥è¨“ç·´æ•¸æ“šè¼‰å…¥"""
    print("\n" + "=" * 80)
    print("ğŸ” æª¢æŸ¥è¨“ç·´æ•¸æ“šè¼‰å…¥")
    print("=" * 80)

    engine = create_engine(BERT_DB_URL, echo=False)

    with Session(engine) as session:
        # è¼‰å…¥å‹•ç•«æ˜ å°„
        animes = session.exec(select(BERTAnime)).all()
        item_to_idx = {anime.id: idx + 1 for idx, anime in enumerate(animes)}
        print(f"âœ“ å‹•ç•«æ˜ å°„å»ºç«‹: {len(item_to_idx)} å€‹é …ç›®")

        # è¼‰å…¥ä½¿ç”¨è€…åºåˆ—
        user_lists = session.exec(select(BERTUserAnimeList)).all()
        print(f"âœ“ è¼‰å…¥è¨˜éŒ„: {len(user_lists)} ç­†")

        # æŒ‰ä½¿ç”¨è€…åˆ†çµ„
        user_sequences_dict = {}
        skipped_count = 0
        for entry in user_lists:
            user_id = entry.user_id
            anime_id = entry.anime_id

            # æª¢æŸ¥æ˜¯å¦åœ¨æ˜ å°„ä¸­
            if anime_id not in item_to_idx:
                skipped_count += 1
                continue

            if user_id not in user_sequences_dict:
                user_sequences_dict[user_id] = []

            user_sequences_dict[user_id].append(anime_id)

        if skipped_count > 0:
            print(f"âš ï¸  è·³é {skipped_count} å€‹ä¸åœ¨æ˜ å°„ä¸­çš„å‹•ç•«")

        # éæ¿¾åºåˆ—
        all_sequences = list(user_sequences_dict.values())
        valid_sequences = [seq for seq in all_sequences if len(seq) >= 5]

        print(f"âœ“ ä½¿ç”¨è€…åºåˆ—: {len(all_sequences)} å€‹")
        print(f"âœ“ æœ‰æ•ˆåºåˆ— (>=5): {len(valid_sequences)} å€‹")

        if valid_sequences:
            seq_lengths = [len(seq) for seq in valid_sequences]
            print(f"âœ“ å¹³å‡åºåˆ—é•·åº¦: {np.mean(seq_lengths):.1f}")
            print(f"âœ“ æœ€é•·åºåˆ—: {max(seq_lengths)}")
            print(f"âœ“ æœ€çŸ­åºåˆ—: {min(seq_lengths)}")
            print(f"âœ“ ä¸­ä½æ•¸: {np.median(seq_lengths):.1f}")

        return len(valid_sequences), seq_lengths if valid_sequences else []


def check_model_files():
    """æª¢æŸ¥æ¨¡å‹æª”æ¡ˆ"""
    print("\n" + "=" * 80)
    print("ğŸ“ æª¢æŸ¥æ¨¡å‹æª”æ¡ˆ")
    print("=" * 80)

    model_dir = Path("bert_model/trained_models")

    if not model_dir.exists():
        print("âŒ æ¨¡å‹ç›®éŒ„ä¸å­˜åœ¨")
        return False

    # æª¢æŸ¥ä¸»è¦æª”æ¡ˆ
    files_to_check = {
        "best_model.pth": "æœ€ä½³æ¨¡å‹",
        "item_mappings.pkl": "é …ç›®æ˜ å°„",
    }

    found_files = []
    for filename, description in files_to_check.items():
        filepath = model_dir / filename
        if filepath.exists():
            size_mb = filepath.stat().st_size / (1024 * 1024)
            print(f"âœ“ {description}: {filename} ({size_mb:.2f} MB)")
            found_files.append(filename)
        else:
            print(f"âŒ {description}: {filename} (ä¸å­˜åœ¨)")

    # æª¢æŸ¥ checkpoint æª”æ¡ˆ
    checkpoint_files = list(model_dir.glob("checkpoint_epoch_*.pth"))
    if checkpoint_files:
        print(f"\nâœ“ æ‰¾åˆ° {len(checkpoint_files)} å€‹ checkpoint æª”æ¡ˆ:")
        for cp in sorted(checkpoint_files)[-5:]:  # é¡¯ç¤ºæœ€å¾Œ 5 å€‹
            size_mb = cp.stat().st_size / (1024 * 1024)
            print(f"  - {cp.name} ({size_mb:.2f} MB)")

    return len(found_files) == len(files_to_check)


def estimate_training_time():
    """ä¼°ç®—è¨“ç·´æ™‚é–“"""
    print("\n" + "=" * 80)
    print("â±ï¸  ä¼°ç®—è¨“ç·´æ™‚é–“")
    print("=" * 80)

    engine = create_engine(BERT_DB_URL, echo=False)

    with Session(engine) as session:
        animes = session.exec(select(BERTAnime)).all()
        user_lists = session.exec(select(BERTUserAnimeList)).all()

        item_to_idx = {anime.id: idx + 1 for idx, anime in enumerate(animes)}

        user_sequences_dict = {}
        for entry in user_lists:
            if entry.anime_id not in item_to_idx:
                continue
            if entry.user_id not in user_sequences_dict:
                user_sequences_dict[entry.user_id] = []
            user_sequences_dict[entry.user_id].append(entry.anime_id)

        valid_sequences = [seq for seq in user_sequences_dict.values() if len(seq) >= 5]

        if not valid_sequences:
            print("âŒ æ²’æœ‰æœ‰æ•ˆçš„è¨“ç·´åºåˆ—")
            return

        # ä¸åŒæ‰¹æ¬¡å¤§å°çš„ä¼°ç®—
        batch_sizes = [8, 16, 32, 64]
        epochs = 20

        print(f"è¨“ç·´åºåˆ—æ•¸: {len(valid_sequences)}")
        print(f"è¨“ç·´è¼ªæ•¸: {epochs}")
        print()

        for batch_size in batch_sizes:
            batches_per_epoch = (len(valid_sequences) + batch_size - 1) // batch_size

            # CPU ä¼°ç®—: ~0.5-1 ç§’/æ‰¹æ¬¡
            # GPU ä¼°ç®—: ~0.1-0.2 ç§’/æ‰¹æ¬¡
            cpu_time_per_batch = 0.75  # ç§’
            gpu_time_per_batch = 0.15  # ç§’

            cpu_total_seconds = batches_per_epoch * epochs * cpu_time_per_batch
            gpu_total_seconds = batches_per_epoch * epochs * gpu_time_per_batch

            print(f"æ‰¹æ¬¡å¤§å° {batch_size}:")
            print(f"  - æ¯è¼ªæ‰¹æ¬¡æ•¸: {batches_per_epoch}")
            print(
                f"  - CPU ä¼°ç®—æ™‚é–“: {cpu_total_seconds / 60:.1f} åˆ†é˜ ({cpu_total_seconds:.0f} ç§’)"
            )
            print(
                f"  - GPU ä¼°ç®—æ™‚é–“: {gpu_total_seconds / 60:.1f} åˆ†é˜ ({gpu_total_seconds:.0f} ç§’)"
            )
            print()

        print("âš ï¸  å¯¦éš›æ™‚é–“æœƒå› ç¡¬é«”ã€åºåˆ—é•·åº¦ã€æ¨¡å‹å¤§å°è€Œç•°")
        print("âš ï¸  å¦‚æœè¨“ç·´åœ¨ 20 ç§’å…§å®Œæˆï¼Œå¯èƒ½æ˜¯:")
        print("     1. è¨“ç·´åºåˆ—å¤ªå°‘ (< 10)")
        print("     2. æ‰¹æ¬¡å¤§å°éå¤§ (æ‰¹æ¬¡æ•¸å¤ªå°‘)")
        print("     3. æ²’æœ‰æ­£ç¢ºè¼‰å…¥æ•¸æ“š")


def main():
    print("\n" + "=" * 80)
    print("ğŸ”¬ BERT è¨“ç·´ç‹€æ…‹æª¢æŸ¥")
    print("=" * 80)

    # 1. æª¢æŸ¥è³‡æ–™åº«
    num_animes, num_records, num_users = check_database()

    # 2. æª¢æŸ¥è¨“ç·´æ•¸æ“šè¼‰å…¥
    num_sequences, seq_lengths = check_training_data()

    # 3. æª¢æŸ¥æ¨¡å‹æª”æ¡ˆ
    has_model = check_model_files()

    # 4. ä¼°ç®—è¨“ç·´æ™‚é–“
    estimate_training_time()

    # ç¸½çµ
    print("\n" + "=" * 80)
    print("ğŸ“‹ ç¸½çµ")
    print("=" * 80)

    if num_users < 10:
        print("âš ï¸  è­¦å‘Š: ä½¿ç”¨è€…æ•¸é‡éå°‘ (< 10)ï¼Œå»ºè­°è‡³å°‘ 30 ä½ä½¿ç”¨è€…")

    if num_sequences < 10:
        print("âš ï¸  è­¦å‘Š: è¨“ç·´åºåˆ—éå°‘ (< 10)ï¼Œé€™æœƒå°è‡´è¨“ç·´æ¥µå¿«å®Œæˆ")
        print("   å»ºè­°: è¼‰å…¥æ›´å¤šä½¿ç”¨è€…æ•¸æ“š")

    if num_sequences >= 30:
        print("âœ… è¨“ç·´åºåˆ—æ•¸é‡å……è¶³")

    if not has_model:
        print("âš ï¸  æ¨¡å‹æª”æ¡ˆä¸å®Œæ•´ï¼Œå»ºè­°é‡æ–°è¨“ç·´")
    else:
        print("âœ… æ¨¡å‹æª”æ¡ˆå®Œæ•´")

    # è¨ºæ–· 20 ç§’å•é¡Œ
    print("\n" + "=" * 80)
    print("ğŸ” è¨ºæ–·: ç‚ºä»€éº¼è¨“ç·´åªéœ€è¦ 20 ç§’?")
    print("=" * 80)

    if num_sequences < 10:
        print("âŒ åŸå› : è¨“ç·´åºåˆ—å¤ªå°‘!")
        print(f"   ç›®å‰åªæœ‰ {num_sequences} å€‹åºåˆ—")
        print("   è§£æ±ºæ–¹æ¡ˆ: ä½¿ç”¨ load_users_from_file.py è¼‰å…¥æ›´å¤šä½¿ç”¨è€…")
    elif num_sequences < 100:
        print("âš ï¸  å¯èƒ½åŸå› : è¨“ç·´åºåˆ—è¼ƒå°‘")
        print(f"   ç›®å‰æœ‰ {num_sequences} å€‹åºåˆ—")
        print("   é€™æ˜¯æ­£å¸¸çš„ï¼Œå°æ–¼å°æ•¸æ“šé›†ï¼Œè¨“ç·´ç¢ºå¯¦æœƒæ¯”è¼ƒå¿«")
        print("   å»ºè­°: é™ä½æ‰¹æ¬¡å¤§å° (ä¾‹å¦‚ 8 æˆ– 16) ä¾†å¢åŠ è¨“ç·´æ­¥æ•¸")
    else:
        print("âœ… è¨“ç·´åºåˆ—æ•¸é‡å……è¶³")
        print("   å¦‚æœä»ç„¶å¾ˆå¿«å®Œæˆï¼Œæª¢æŸ¥:")
        print("   1. æ‰¹æ¬¡å¤§å°æ˜¯å¦éå¤§")
        print("   2. æ˜¯å¦ä½¿ç”¨äº† GPU")
        print("   3. æª¢æŸ¥è¨“ç·´æ—¥èªŒä¸­çš„æ‰¹æ¬¡æ•¸")

    print("\nâœ… æª¢æŸ¥å®Œæˆ!")


if __name__ == "__main__":
    main()
