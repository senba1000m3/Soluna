"""
BERT4Rec æ¨¡å‹è¨“ç·´è…³æœ¬
ä½¿ç”¨æº–å‚™å¥½çš„è³‡æ–™é›†è¨“ç·´æ¨è–¦æ¨¡å‹

ä½¿ç”¨æ–¹å¼:
    python train_bert_model.py
    python train_bert_model.py --epochs 50 --batch-size 128
    python train_bert_model.py --gpu --fp16
"""

import argparse
import json
import logging
import pickle
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Tuple

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sqlmodel import Session, create_engine, select
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm

# Fix Windows encoding issue
if sys.platform == "win32":
    import codecs

    # Check if stdout/stderr have buffer attribute (not in uv run)
    if hasattr(sys.stdout, "buffer"):
        sys.stdout = codecs.getwriter("utf-8")(sys.stdout.buffer, "strict")
        sys.stderr = codecs.getwriter("utf-8")(sys.stderr.buffer, "strict")

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("train_bert_model.log", encoding="utf-8"),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)

# è³‡æ–™åº«è·¯å¾‘
BERT_DB_PATH = "bert.db"
BERT_DB_URL = f"sqlite:///{BERT_DB_PATH}"

# æ¨¡å‹è¼¸å‡ºç›®éŒ„
OUTPUT_DIR = Path("bert_models")
OUTPUT_DIR.mkdir(exist_ok=True)


# ============================================================================
# è¼‰å…¥è³‡æ–™åº«æ¨¡å‹
# ============================================================================

from prepare_bert_dataset import BERTAnime, BERTUserAnimeList

# ============================================================================
# BERT4Rec æ¨¡å‹æ¶æ§‹
# ============================================================================


class BERT4Rec(nn.Module):
    """
    BERT4Rec æ¨¡å‹å¯¦ç¾
    åŸºæ–¼ Transformer Encoder çš„åºåˆ—æ¨è–¦æ¨¡å‹
    """

    def __init__(
        self,
        num_items: int,
        max_seq_len: int = 200,
        hidden_size: int = 256,
        num_layers: int = 2,
        num_heads: int = 4,
        dropout: float = 0.1,
    ):
        """
        åˆå§‹åŒ– BERT4Rec æ¨¡å‹

        Args:
            num_items: å‹•ç•«ç¸½æ•¸
            max_seq_len: æœ€å¤§åºåˆ—é•·åº¦
            hidden_size: éš±è—å±¤ç¶­åº¦
            num_layers: Transformer å±¤æ•¸
            num_heads: æ³¨æ„åŠ›é ­æ•¸
            dropout: Dropout æ¯”ç‡
        """
        super().__init__()

        self.num_items = num_items
        self.max_seq_len = max_seq_len
        self.hidden_size = hidden_size

        # Token embeddings
        # +3 for [PAD], [MASK], [CLS] tokens
        self.item_embedding = nn.Embedding(num_items + 3, hidden_size, padding_idx=0)

        # Position embeddings
        self.position_embedding = nn.Embedding(max_seq_len, hidden_size)

        # Transformer Encoder
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=hidden_size,
            nhead=num_heads,
            dim_feedforward=hidden_size * 4,
            dropout=dropout,
            batch_first=True,
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

        # Output layer (num_items + 3 for PAD, MASK, CLS)
        self.out = nn.Linear(hidden_size, num_items + 3)

        self.dropout = nn.Dropout(dropout)
        self.layer_norm = nn.LayerNorm(hidden_size)

        # Special tokens
        self.pad_token = 0
        self.mask_token = num_items + 1
        self.cls_token = num_items + 2

    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor = None):
        """
        å‰å‘å‚³æ’­

        Args:
            input_ids: [batch_size, seq_len]
            attention_mask: [batch_size, seq_len]

        Returns:
            logits: [batch_size, seq_len, num_items]
        """
        batch_size, seq_len = input_ids.size()

        # Item embeddings
        item_emb = self.item_embedding(input_ids)  # [B, L, H]

        # Position embeddings
        position_ids = torch.arange(seq_len, device=input_ids.device)
        position_ids = position_ids.unsqueeze(0).expand(batch_size, -1)
        position_emb = self.position_embedding(position_ids)  # [B, L, H]

        # Combine embeddings
        embeddings = item_emb + position_emb
        embeddings = self.layer_norm(embeddings)
        embeddings = self.dropout(embeddings)

        # Create attention mask for padding
        if attention_mask is None:
            attention_mask = (input_ids != self.pad_token).float()

        # Transformer expects mask of shape [batch, seq_len]
        # with 1 for tokens to attend to, 0 for padding
        # We need to invert it: 1 -> 0, 0 -> -inf
        extended_attention_mask = (1.0 - attention_mask) * -10000.0

        # Transformer encoding
        hidden_states = self.transformer(
            embeddings, src_key_padding_mask=(attention_mask == 0)
        )

        # Output projection
        logits = self.out(hidden_states)  # [B, L, num_items]

        return logits


# ============================================================================
# è³‡æ–™é›†
# ============================================================================


class BERT4RecDataset(Dataset):
    """BERT4Rec è¨“ç·´è³‡æ–™é›†"""

    def __init__(
        self,
        user_sequences: List[List[int]],
        item_to_idx: Dict[int, int],
        max_seq_len: int = 200,
        mask_prob: float = 0.15,
        mask_token: int = None,
    ):
        """
        åˆå§‹åŒ–è³‡æ–™é›†

        Args:
            user_sequences: ä½¿ç”¨è€…è§€çœ‹åºåˆ—åˆ—è¡¨
            item_to_idx: å‹•ç•« ID åˆ°ç´¢å¼•çš„æ˜ å°„
            max_seq_len: æœ€å¤§åºåˆ—é•·åº¦
            mask_prob: é®ç½©æ¦‚ç‡
            mask_token: é®ç½© token ID
        """
        self.user_sequences = user_sequences
        self.item_to_idx = item_to_idx
        self.max_seq_len = max_seq_len
        self.mask_prob = mask_prob
        self.mask_token = mask_token
        self.num_items = len(item_to_idx)
        self.pad_token = 0

    def __len__(self):
        return len(self.user_sequences)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        å–å¾—è¨“ç·´æ¨£æœ¬

        Returns:
            input_ids: é®ç½©å¾Œçš„åºåˆ—
            labels: åŸå§‹åºåˆ—
            attention_mask: æ³¨æ„åŠ›é®ç½©
        """
        # å–å¾—åºåˆ—ä¸¦è½‰æ›ç‚ºç´¢å¼•
        sequence = self.user_sequences[idx]
        # åªä¿ç•™æœ‰æ•ˆçš„å‹•ç•« IDï¼ˆåœ¨æ˜ å°„ä¸­çš„ï¼‰
        sequence = [
            self.item_to_idx[item] for item in sequence if item in self.item_to_idx
        ]

        # å¦‚æœéæ¿¾å¾Œåºåˆ—ç‚ºç©ºï¼Œä½¿ç”¨ padding
        if not sequence:
            sequence = [self.pad_token]

        # æˆªæ–·æˆ–å¡«å……åˆ° max_seq_len
        if len(sequence) > self.max_seq_len:
            sequence = sequence[-self.max_seq_len :]
        else:
            sequence = [self.pad_token] * (self.max_seq_len - len(sequence)) + sequence

        # è½‰æ›ç‚º tensor
        labels = torch.tensor(sequence, dtype=torch.long)

        # å»ºç«‹é®ç½©åºåˆ—
        input_ids = labels.clone()
        attention_mask = (input_ids != self.pad_token).long()

        # éš¨æ©Ÿé®ç½©éƒ¨åˆ† token
        mask_positions = torch.rand(self.max_seq_len) < self.mask_prob
        # ä¸é®ç½© padding
        mask_positions = mask_positions & (input_ids != self.pad_token)

        if self.mask_token is not None:
            input_ids[mask_positions] = self.mask_token

        return input_ids, labels, attention_mask


# ============================================================================
# è¨“ç·´å™¨
# ============================================================================


class BERT4RecTrainer:
    """BERT4Rec è¨“ç·´å™¨"""

    def __init__(
        self,
        model: BERT4Rec,
        device: torch.device,
        learning_rate: float = 1e-3,
        use_fp16: bool = False,
    ):
        self.model = model.to(device)
        self.device = device
        self.use_fp16 = use_fp16

        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        self.criterion = nn.CrossEntropyLoss(
            ignore_index=0, reduction="mean"
        )  # å¿½ç•¥ padding

        # FP16 training
        if use_fp16 and device.type == "cuda":
            self.scaler = torch.cuda.amp.GradScaler()
            logger.info("âœ… å•Ÿç”¨ FP16 è¨“ç·´")
        else:
            self.scaler = None

        self.train_losses = []
        self.val_losses = []

    def train_epoch(self, dataloader: DataLoader) -> float:
        """è¨“ç·´ä¸€å€‹ epoch"""
        self.model.train()
        total_loss = 0
        num_batches = 0

        progress_bar = tqdm(dataloader, desc="è¨“ç·´ä¸­", unit="batch")
        for input_ids, labels, attention_mask in progress_bar:
            input_ids = input_ids.to(self.device)
            labels = labels.to(self.device)
            attention_mask = attention_mask.to(self.device)

            self.optimizer.zero_grad()

            # Forward pass
            if self.use_fp16 and self.scaler:
                with torch.cuda.amp.autocast():
                    logits = self.model(input_ids, attention_mask)
                    # Reshape for CrossEntropyLoss
                    logits = logits.view(-1, logits.size(-1))
                    labels = labels.view(-1)
                    loss = self.criterion(logits, labels)

                # Backward pass with mixed precision
                self.scaler.scale(loss).backward()
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                logits = self.model(input_ids, attention_mask)
                logits = logits.view(-1, logits.size(-1))
                labels = labels.view(-1)
                loss = self.criterion(logits, labels)

                # Backward pass
                loss.backward()
                self.optimizer.step()

            total_loss += loss.item()
            num_batches += 1

            progress_bar.set_postfix({"loss": f"{loss.item():.4f}"})

        avg_loss = total_loss / num_batches
        self.train_losses.append(avg_loss)
        return avg_loss

    @torch.no_grad()
    def validate(self, dataloader: DataLoader) -> float:
        """é©—è­‰"""
        self.model.eval()
        total_loss = 0
        num_batches = 0

        for input_ids, labels, attention_mask in tqdm(
            dataloader, desc="é©—è­‰ä¸­", unit="batch"
        ):
            input_ids = input_ids.to(self.device)
            labels = labels.to(self.device)
            attention_mask = attention_mask.to(self.device)

            logits = self.model(input_ids, attention_mask)
            logits = logits.view(-1, logits.size(-1))
            labels = labels.view(-1)
            loss = self.criterion(logits, labels)

            total_loss += loss.item()
            num_batches += 1

        avg_loss = total_loss / num_batches
        self.val_losses.append(avg_loss)
        return avg_loss

    def save_checkpoint(self, epoch: int, filepath: Path) -> None:
        """å„²å­˜ checkpoint"""
        checkpoint = {
            "epoch": epoch,
            "model_state_dict": self.model.state_dict(),
            "optimizer_state_dict": self.optimizer.state_dict(),
            "train_losses": self.train_losses,
            "val_losses": self.val_losses,
            "model_config": {
                "num_items": self.model.num_items,
                "max_seq_len": self.model.max_seq_len,
                "hidden_size": self.model.hidden_size,
            },
        }
        torch.save(checkpoint, filepath)
        logger.info(f"ğŸ’¾ Checkpoint å·²å„²å­˜: {filepath}")


# ============================================================================
# è³‡æ–™è¼‰å…¥èˆ‡é è™•ç†
# ============================================================================


def load_dataset_from_db() -> Tuple[List[List[int]], Dict[int, int], int]:
    """
    å¾è³‡æ–™åº«è¼‰å…¥è³‡æ–™é›†

    Returns:
        user_sequences: ä½¿ç”¨è€…åºåˆ—åˆ—è¡¨
        item_to_idx: å‹•ç•« ID åˆ°ç´¢å¼•çš„æ˜ å°„
        num_items: å‹•ç•«ç¸½æ•¸
    """
    print("\n" + "=" * 80)
    print("ğŸ“š è¼‰å…¥è³‡æ–™é›†")
    print("=" * 80)

    engine = create_engine(BERT_DB_URL, echo=False)

    with Session(engine) as session:
        # è¼‰å…¥æ‰€æœ‰å‹•ç•«
        animes = session.exec(select(BERTAnime)).all()
        num_items = len(animes)
        print(f"  âœ“ å‹•ç•«ç¸½æ•¸: {num_items}")

        # å»ºç«‹ ID æ˜ å°„ (AniList ID -> æ¨¡å‹ç´¢å¼•)
        # ä¿ç•™ 0 çµ¦ padding, num_items+1 çµ¦ mask, num_items+2 çµ¦ cls
        item_to_idx = {anime.id: idx + 1 for idx, anime in enumerate(animes)}
        idx_to_item = {idx + 1: anime.id for idx, anime in enumerate(animes)}

        print(f"  âœ“ ID æ˜ å°„å»ºç«‹å®Œæˆ")

        # è¼‰å…¥ä½¿ç”¨è€…åºåˆ—
        user_lists = session.exec(select(BERTUserAnimeList)).all()
        print(f"  âœ“ ä½¿ç”¨è€…åˆ—è¡¨è¨˜éŒ„: {len(user_lists)}")

        # æŒ‰ä½¿ç”¨è€…åˆ†çµ„
        user_sequences_dict = {}
        skipped_count = 0
        for entry in user_lists:
            user_id = entry.user_id
            anime_id = entry.anime_id

            # ä½¿ç”¨æ‰€æœ‰ç‹€æ…‹çš„å‹•ç•«ï¼ˆCOMPLETED, CURRENT, PLANNING, DROPPED, PAUSED ç­‰ï¼‰
            # ä¸éæ¿¾ç‹€æ…‹ï¼Œå› ç‚ºä½¿ç”¨è€…çš„è§€çœ‹è¨˜éŒ„éƒ½æœ‰åƒè€ƒåƒ¹å€¼

            # æª¢æŸ¥å‹•ç•« ID æ˜¯å¦åœ¨æ˜ å°„ä¸­
            if anime_id not in item_to_idx:
                skipped_count += 1
                continue

            if user_id not in user_sequences_dict:
                user_sequences_dict[user_id] = []

            user_sequences_dict[user_id].append(anime_id)

        if skipped_count > 0:
            print(f"  âš ï¸  è·³é {skipped_count} å€‹ä¸åœ¨è³‡æ–™åº«ä¸­çš„å‹•ç•«")

        # è½‰æ›ç‚ºåˆ—è¡¨
        user_sequences = list(user_sequences_dict.values())

        # éæ¿¾å¤ªçŸ­çš„åºåˆ— (è‡³å°‘ 5 éƒ¨)
        user_sequences = [seq for seq in user_sequences if len(seq) >= 5]

        print(f"  âœ“ æœ‰æ•ˆä½¿ç”¨è€…æ•¸: {len(user_sequences)}")
        print(f"  âœ“ å¹³å‡åºåˆ—é•·åº¦: {np.mean([len(seq) for seq in user_sequences]):.1f}")
        print(f"  âœ“ æœ€é•·åºåˆ—: {max(len(seq) for seq in user_sequences)}")
        print(f"  âœ“ æœ€çŸ­åºåˆ—: {min(len(seq) for seq in user_sequences)}")

    return user_sequences, item_to_idx, idx_to_item, num_items


def split_dataset(
    user_sequences: List[List[int]], val_ratio: float = 0.1
) -> Tuple[List[List[int]], List[List[int]]]:
    """åˆ†å‰²è¨“ç·´é›†å’Œé©—è­‰é›†"""
    num_val = int(len(user_sequences) * val_ratio)
    num_train = len(user_sequences) - num_val

    # éš¨æ©Ÿæ‰“äº‚
    indices = np.random.permutation(len(user_sequences))
    train_indices = indices[:num_train]
    val_indices = indices[num_train:]

    train_sequences = [user_sequences[i] for i in train_indices]
    val_sequences = [user_sequences[i] for i in val_indices]

    return train_sequences, val_sequences


# ============================================================================
# ä¸»ç¨‹å¼
# ============================================================================


def main():
    parser = argparse.ArgumentParser(
        description="è¨“ç·´ BERT4Rec æ¨è–¦æ¨¡å‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  # åŸºæœ¬è¨“ç·´
  python train_bert_model.py

  # ä½¿ç”¨ GPU å’Œ FP16
  python train_bert_model.py --gpu --fp16

  # è‡ªè¨‚åƒæ•¸
  python train_bert_model.py --epochs 50 --batch-size 128 --lr 0.001

  # å¾ checkpoint ç¹¼çºŒè¨“ç·´
  python train_bert_model.py --resume bert_models/checkpoint_epoch_10.pth
        """,
    )

    # è¨“ç·´åƒæ•¸
    parser.add_argument("--epochs", type=int, default=30, help="è¨“ç·´è¼ªæ•¸ (é è¨­: 30)")
    parser.add_argument(
        "--batch-size", type=int, default=64, help="æ‰¹æ¬¡å¤§å° (é è¨­: 64)"
    )
    parser.add_argument("--lr", type=float, default=1e-3, help="å­¸ç¿’ç‡ (é è¨­: 0.001)")
    parser.add_argument(
        "--val-ratio", type=float, default=0.1, help="é©—è­‰é›†æ¯”ä¾‹ (é è¨­: 0.1)"
    )

    # æ¨¡å‹åƒæ•¸
    parser.add_argument(
        "--hidden-size", type=int, default=256, help="éš±è—å±¤å¤§å° (é è¨­: 256)"
    )
    parser.add_argument(
        "--num-layers", type=int, default=2, help="Transformer å±¤æ•¸ (é è¨­: 2)"
    )
    parser.add_argument("--num-heads", type=int, default=4, help="æ³¨æ„åŠ›é ­æ•¸ (é è¨­: 4)")
    parser.add_argument(
        "--max-seq-len", type=int, default=200, help="æœ€å¤§åºåˆ—é•·åº¦ (é è¨­: 200)"
    )
    parser.add_argument(
        "--dropout", type=float, default=0.1, help="Dropout (é è¨­: 0.1)"
    )

    # ç¡¬é«”
    parser.add_argument("--gpu", action="store_true", help="ä½¿ç”¨ GPU")
    parser.add_argument("--fp16", action="store_true", help="ä½¿ç”¨ FP16 è¨“ç·´")

    # å…¶ä»–
    parser.add_argument("--resume", type=str, help="å¾ checkpoint ç¹¼çºŒè¨“ç·´")
    parser.add_argument("--seed", type=int, default=42, help="éš¨æ©Ÿç¨®å­ (é è¨­: 42)")

    args = parser.parse_args()

    # è¨­å®šéš¨æ©Ÿç¨®å­
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)

    # è¨­å®šè£ç½®
    if args.gpu and torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"âœ… ä½¿ç”¨ GPU: {torch.cuda.get_device_name(0)}")
    else:
        device = torch.device("cpu")
        print("âš ï¸  ä½¿ç”¨ CPU (å»ºè­°ä½¿ç”¨ GPU ä»¥åŠ é€Ÿè¨“ç·´)")

    print("\n" + "=" * 80)
    print("ğŸš€ BERT4Rec æ¨¡å‹è¨“ç·´")
    print("=" * 80)
    print(f"  è¨“ç·´è¼ªæ•¸: {args.epochs}")
    print(f"  æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"  å­¸ç¿’ç‡: {args.lr}")
    print(f"  æœ€å¤§åºåˆ—é•·åº¦: {args.max_seq_len}")
    print(f"  éš±è—å±¤å¤§å°: {args.hidden_size}")
    print(f"  Transformer å±¤æ•¸: {args.num_layers}")
    print(f"  æ³¨æ„åŠ›é ­æ•¸: {args.num_heads}")
    print(f"  FP16: {'å•Ÿç”¨' if args.fp16 else 'åœç”¨'}")
    print("=" * 80)

    try:
        # è¼‰å…¥è³‡æ–™
        user_sequences, item_to_idx, idx_to_item, num_items = load_dataset_from_db()

        if len(user_sequences) == 0:
            print("\nâŒ éŒ¯èª¤: æ²’æœ‰å¯ç”¨çš„è¨“ç·´è³‡æ–™")
            print("è«‹å…ˆåŸ·è¡Œ: python prepare_bert_dataset.py --users USERNAME")
            sys.exit(1)

        # åˆ†å‰²è³‡æ–™
        train_sequences, val_sequences = split_dataset(
            user_sequences, val_ratio=args.val_ratio
        )
        print(f"\n  è¨“ç·´é›†: {len(train_sequences)} å€‹åºåˆ—")
        print(f"  é©—è­‰é›†: {len(val_sequences)} å€‹åºåˆ—")

        # å»ºç«‹è³‡æ–™é›†
        mask_token = num_items + 1
        train_dataset = BERT4RecDataset(
            train_sequences, item_to_idx, args.max_seq_len, mask_token=mask_token
        )
        val_dataset = BERT4RecDataset(
            val_sequences, item_to_idx, args.max_seq_len, mask_token=mask_token
        )

        # å»ºç«‹ DataLoader
        train_loader = DataLoader(
            train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=0
        )
        val_loader = DataLoader(
            val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0
        )

        # å»ºç«‹æ¨¡å‹
        model = BERT4Rec(
            num_items=num_items,
            max_seq_len=args.max_seq_len,
            hidden_size=args.hidden_size,
            num_layers=args.num_layers,
            num_heads=args.num_heads,
            dropout=args.dropout,
        )

        print(f"\nâœ… æ¨¡å‹å»ºç«‹å®Œæˆ")
        total_params = sum(p.numel() for p in model.parameters())
        print(f"  ç¸½åƒæ•¸é‡: {total_params:,}")

        # å»ºç«‹è¨“ç·´å™¨
        trainer = BERT4RecTrainer(
            model, device, learning_rate=args.lr, use_fp16=args.fp16 and args.gpu
        )

        # è¨“ç·´
        print("\n" + "=" * 80)
        print("ğŸ¯ é–‹å§‹è¨“ç·´")
        print("=" * 80)

        best_val_loss = float("inf")
        start_epoch = 1

        for epoch in range(start_epoch, args.epochs + 1):
            print(f"\nğŸ“‹ Epoch {epoch}/{args.epochs}")
            print("-" * 80)

            # è¨“ç·´
            train_loss = trainer.train_epoch(train_loader)
            print(f"  è¨“ç·´ Loss: {train_loss:.4f}")

            # é©—è­‰
            val_loss = trainer.validate(val_loader)
            print(f"  é©—è­‰ Loss: {val_loss:.4f}")

            # å„²å­˜ checkpoint
            if epoch % 5 == 0 or epoch == args.epochs:
                checkpoint_path = OUTPUT_DIR / f"checkpoint_epoch_{epoch}.pth"
                trainer.save_checkpoint(epoch, checkpoint_path)

            # å„²å­˜æœ€ä½³æ¨¡å‹
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                best_model_path = OUTPUT_DIR / "best_model.pth"
                trainer.save_checkpoint(epoch, best_model_path)
                print(f"  ğŸŒŸ æ–°çš„æœ€ä½³æ¨¡å‹ï¼é©—è­‰ Loss: {val_loss:.4f}")

        # è¨“ç·´å®Œæˆ
        print("\n" + "=" * 80)
        print("ğŸ‰ è¨“ç·´å®Œæˆï¼")
        print("=" * 80)
        print(f"  æœ€ä½³é©—è­‰ Loss: {best_val_loss:.4f}")
        print(f"  æ¨¡å‹å·²å„²å­˜è‡³: {OUTPUT_DIR}")

        # å„²å­˜æ˜ å°„è³‡æ–™
        mapping_path = OUTPUT_DIR / "item_mappings.pkl"
        with open(mapping_path, "wb") as f:
            pickle.dump(
                {
                    "item_to_idx": item_to_idx,
                    "idx_to_item": idx_to_item,
                    "num_items": num_items,
                },
                f,
            )
        print(f"  æ˜ å°„è³‡æ–™å·²å„²å­˜: {mapping_path}")

        print("\nğŸ“ ä¸‹ä¸€æ­¥:")
        print("  1. æ¸¬è©¦æ¨¡å‹: python test_bert_model.py")
        print("  2. æ•´åˆåˆ°æ¨è–¦ç³»çµ±: ä¿®æ”¹ hybrid_recommendation_engine.py")

    except KeyboardInterrupt:
        print("\n\nâš ï¸  è¨“ç·´è¢«ä¸­æ–·")
        sys.exit(130)
    except Exception as e:
        logger.error(f"è¨“ç·´å¤±æ•—: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()
